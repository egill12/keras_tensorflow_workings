{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This file is a simple implementation of the \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "model = Sequential()\n",
    "eurusd_train = pd.read_csv(r\"/storage/eurusd_train_normed.csv\")\n",
    "eurusd_test = pd.read_csv(r\"/storage/eurusd_test_normed.csv\")\n",
    "eurusd_train = eurusd_train.replace(np.nan, 0)\n",
    "eurusd_test = eurusd_test.replace(np.nan, 0)\n",
    "\n",
    "# TODO Friday-> Tomorrow\n",
    "# Get LSTM model working with your train,test data first\n",
    "# get it learning and giving output. Then look to refine the model. think about the target, how will we create probability distributions? \n",
    "# get the EURUSD data\n",
    "# Chose the trainign size of the data\n",
    "DATA_SIZE = 475\n",
    "#npData.shape\n",
    "train_original = eurusd_train.iloc[-DATA_SIZE:,:]\n",
    "test_original = eurusd_test.iloc[:DATA_SIZE,:]\n",
    "features_to_use = [\"spot_v_HF\", \"spot_v_MF\", \"spot_v_LF\", \"HF_ema_diff\", \"MF_ema_diff\",\"LF_ema_diff\", \"LDN\", \"NY\", \"Asia\", \"target\"]\n",
    "# Data needs to be reshaped into 3D tensor\n",
    "train_sample = eurusd_train[features_to_use].iloc[-DATA_SIZE:,:].values\n",
    "test_sample = eurusd_test[features_to_use].iloc[:DATA_SIZE,:].values\n",
    "#sample_data['target'] = 1\n",
    "#target.shape\n",
    "# this creates your dataset with the lookback periods it needs to use.\n",
    "\n",
    "import numpy as np\n",
    "# this lookbacks over a set period as the memory for the LSTM\n",
    "look_back = 60\n",
    "def create_dataset(dataset, populate_target ,look_back=look_back):\n",
    "  dataX, dataY, target_dates = [], [], []\n",
    "  for i in range(len(dataset)-look_back+1):\n",
    "      # this takes the very last col as the target\n",
    "    a = dataset[i:(i+look_back), :-1]\n",
    "    dataX.append(a)\n",
    "    # this code assumes that the target vector is the very last col.\n",
    "    dataY.append(dataset[i + look_back - 1, -1])\n",
    "    if populate_target:\n",
    "        target_dates.append(test_original['Date'].loc[i + look_back - 1])\n",
    "  return np.array(dataX), np.array(dataY), target_dates\n",
    "\n",
    "train_sample_transformed = create_dataset(train_sample,False, look_back)\n",
    "train_data = train_sample_transformed[0]\n",
    "train_target = train_sample_transformed[1]\n",
    "\n",
    "test_sample_transformed = create_dataset(test_sample, True, look_back)\n",
    "test_data = test_sample_transformed[0]\n",
    "test_target = test_sample_transformed[1]\n",
    "target_dates = test_sample_transformed[2]\n",
    "\n",
    "# reshape sems to add another list around every observation\n",
    "train_data = train_data.reshape(train_data.shape[0], look_back, train_data.shape[2])\n",
    "train_target = train_target.reshape(train_target.shape[0], 1)\n",
    "\n",
    "test_data = test_data.reshape(test_data.shape[0], look_back, test_data.shape[2])\n",
    "test_target = test_target.reshape(test_target.shape[0], 1)\n",
    "\n",
    "BATCH_SIZE = 300\n",
    "no_features = train_data.shape[2]\n",
    "model = Sequential()\n",
    "model.add(LSTM(4,batch_input_shape = (None,look_back,no_features), return_sequences = True))\n",
    "model.add(LSTM(1, return_sequences = False, activation=\"softmax\"))\n",
    "#model.add(Dense(2, activation= \"softmax\"))\n",
    "model.compile(loss = \"mean_absolute_error\", optimizer=\"adam\", metrics = ['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_data,train_target,epochs = 1000,validation_data=(test_data,test_target), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mergeing signals to the df\n",
    "predictions = pd.DataFrame({\"Date\" : target_dates,\"Predictions\": predicted})\n",
    "test_original = pd.merge(test_original,predictions,how=\"left\", on=\"Date\").fillna(0)\n",
    "test_original.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_horizon = 24\n",
    "test_original[\"scaled_signal\"] = test_original['Predictions'].shift(2).rolling(trade_horizon).sum()/trade_horizon\n",
    "# no shift needed as we have already done that inpervious step\n",
    "test_original['strat_returns'] = test_original['logret']*test_original['scaled_signal']\n",
    "test_original['strat_returns_sum'] = test_original['strat_returns'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = plt.plot()\n",
    "s1 = test_original['CCY']\n",
    "plt.plot(s1,'b')\n",
    "plt.ylabel('Ret',color='b')\n",
    "ax2 = plt.gca().twinx()\n",
    "s2 = test_original['strat_returns_sum'].loc[test_original['scaled_signal'] <0]\n",
    "ax2.plot(s2, 'r*')\n",
    "plt.ylabel('sin', color='r')\n",
    "s3 = test_original['strat_returns_sum'].loc[test_original['scaled_signal'] >0]\n",
    "ax2.plot(s3, 'g*')\n",
    "plt.show()\n",
    "test_original.to_csv(r\"/storage/signal_prediction_test.csv\",index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
